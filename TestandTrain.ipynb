{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "TestandTrain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPrVYYISs_hm",
        "colab_type": "text"
      },
      "source": [
        "**Why do I want to have regression analysis? What's the point?**\n",
        "\n",
        "Three major uses for regression analysis are:\n",
        "\n",
        "1.   determining the strength of predictors\n",
        "2.   forecasting an effect\n",
        "3.   trend forecasting\n",
        "\n",
        "\n",
        "First, the regression might be used to identify the strength of the effect that the independent variable(s) have on a dependent variable. \n",
        "\n",
        "Second, it can be used to forecast effects or impact of changes.  That is, the regression analysis helps us to understand how much the dependent variable changes with a change in one or more independent variables.  \n",
        "\n",
        "Third, regression analysis predicts trends and future values.  The regression analysis can be used to get point estimates.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IJTVgtGj_iJ",
        "colab_type": "text"
      },
      "source": [
        "**Time to get down and dirty with linear regression**\n",
        "\n",
        "Let's play around with some data. For this example, we are going to need to import the necessary packages, datasets, and metrics from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3yFcs3XABA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "boston = datasets.load_boston()\n",
        "print(boston.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkvl2KFDk49L",
        "colab_type": "text"
      },
      "source": [
        "We now need to divide that data we just loaded into usable sets. In order to simplifly the computation, we will be taking only feature from the available 13. For our exercise, the third feature from the Boston House-Prices dataset will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15uyLu2KkBk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Boston House-Prices dataset\n",
        "housing_X, housing_y = datasets.load_boston(return_X_y=True)\n",
        "\n",
        "# Use only one feature\n",
        "housing_X = housing_X[:, np.newaxis, 5]\n",
        "\n",
        "print(\"We are going to take the RM feature which is the average number of rooms per dwelling\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkEru_-ck5lm",
        "colab_type": "text"
      },
      "source": [
        "Time to create the training and testing sets to use in our regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDKhOG0TkCEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "housing_X_train = housing_X[:-40]\n",
        "housing_X_test = housing_X[-40:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "housing_y_train = housing_y[:-40]\n",
        "housing_y_test = housing_y[-40:]\n",
        "\n",
        "print(\"You can fiddle around with how many data points you want for your training and test sets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuDP5bf3k6LY",
        "colab_type": "text"
      },
      "source": [
        "Regression Time! \n",
        "\n",
        "We are now at the part that we have all been waiting for. \n",
        "\n",
        "First, we have to create the regression object from the linear model. \n",
        "\n",
        "Second, it's time to train our model using the training sets that we created earlier. \n",
        "\n",
        "Third, we create the price prediction from the INDUS test set that we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7rUnvT-kB9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(housing_X_train, housing_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "housing_y_pred = regr.predict(housing_X_test)\n",
        "\n",
        "print(\"Regression Complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsPc7lVNk6vO",
        "colab_type": "text"
      },
      "source": [
        "Let see some results of our tests.\n",
        "\n",
        "**Coefficients:** Regression coefficients are estimates of the unknown population parameters and describe the relationship between a predictor variable and the response. In linear regression, coefficients are the values that multiply the predictor values.\n",
        "\n",
        "**MSE:** The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences.\n",
        "\n",
        "**R2 Score:** R-squared is a statistical measure of how close the data is to the fitted regression line. Whereas correlation explains the strength of the relationship between an independent and dependent variable, R-squared explains to what extent the variance of one variable explains the variance of the second variable. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuYUFZakBT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f'\n",
        "      % mean_squared_error(housing_y_test, housing_y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination: %.2f'\n",
        "      % r2_score(housing_y_test, housing_y_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmUOojxOk7Pu",
        "colab_type": "text"
      },
      "source": [
        "Now for the fruits of our labor. Our results in a visual representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKqcMttkBM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot outputs\n",
        "plt.scatter(housing_X_test, housing_y_test,  color='black')\n",
        "plt.plot(housing_X_test, housing_y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xlabel(\"Avg # of rooms per dwelling\")\n",
        "plt.ylabel(\"House Price\")\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w32nGCd-wsrZ",
        "colab_type": "text"
      },
      "source": [
        "**We have all this data but how do we organize it? Logistic Regression to the rescue!**\n",
        "\n",
        "What do you do when when you need to make a decision based on a set of data? How does one organzie the information received? Well have no fear, logistic regression is here to save the day! \n",
        "\n",
        "**Logistic Regression? What is that?**\n",
        "\n",
        "In statistics, the logistic regresion is the appropriate regression analysis to conduct when the dependent variable is dichotomous or binary.  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndylPttItNA9",
        "colab_type": "text"
      },
      "source": [
        "**Let's dip our toe into the logistic regression waters**\n",
        "\n",
        "Here we are going to play around with the Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxX2DSHHLY_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = LogisticRegression(random_state=0).fit(X,y)\n",
        "\n",
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm78tz3_y3uS",
        "colab_type": "text"
      },
      "source": [
        "**Time for some quick maths...for our computers**\n",
        "\n",
        "The predict() function will predict the class labels for our sample.\n",
        "\n",
        "The predict_proba() function calculates the probability estimates.\n",
        "\n",
        "The score() function returns the mean accuracy on the given test data and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v65KJOPiyZQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(clf.predict(X[:2, :]))\n",
        "print(clf.predict_proba(X[:2, :]))\n",
        "print(clf.score(X,y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxEkd7r3Ra3A",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression vs Logistic Regression. Ready? Fight!**\n",
        "\n",
        "So what is the difference between a linear regression and a logistic regression? \n",
        "\n",
        "\n",
        "1.   Linear regression is a supervised regression model while a logistic regression is a supervised classification model\n",
        "2.   Linear regression has a continuous response variable (eg. weight, height, etc.) while a logisitc regression has response variables that are categorical in nature (eg. yes/no, red/green/blue, etc.)\n",
        "3.  Linear is based on the least square estimation while logistic is based on maximum likelihood estimation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrX-QSzDvKzz",
        "colab_type": "text"
      },
      "source": [
        "**Let's do another logistic regression with the same dataset but visualize our output**\n",
        "\n",
        "Like with our linear regression exercise, we need to import the necessary packages, datasets, and models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYqrRoSGxtiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "\n",
        "# import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmndh60lvLTR",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our Iris dataset loaded, it is time to grab features and a target for our regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gG0oWopu5XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = iris.data[:, :2]  # we only take the first two features.\n",
        "Y = iris.target\n",
        "\n",
        "print(\"data\", X)\n",
        "print(\"target\", Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Yd_v2LvL89",
        "colab_type": "text"
      },
      "source": [
        "Once we have our sets we will then create a Logistic Regression Classifier instance and fit the data to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb9tDCoiu5j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an instance of Logistic Regression Classifier and fit the data.\n",
        "logreg = LogisticRegression(C=1e5)\n",
        "\n",
        "logreg.fit(X, Y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_uLSqAHvMcv",
        "colab_type": "text"
      },
      "source": [
        "Time to plot our data. First, we need to create decision boundaries. \n",
        "\n",
        "**Decision Boundary:** a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class or classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYcMQZXu5-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = .02  # step size in the mesh\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46vDwEMFvNGv",
        "colab_type": "text"
      },
      "source": [
        "Let's add a splash of color! \n",
        "\n",
        "Also we are going to plot our training points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQPt3EPlu5tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(4, 3))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "# Plot also the training points\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot also the training points\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}